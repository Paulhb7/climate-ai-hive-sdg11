# Hive.ai - Plateforme d'IA pour le D√©veloppement Durable

Hive.ai est une plateforme qui utilise l'intelligence artificielle pour analyser l'impact du changement climatique sur les villes et fournir des recommandations pour un d√©veloppement urbain durable, align√© avec les Objectifs de D√©veloppement Durable (ODD) de l'ONU.

## üöÄ Fonctionnalit√©s

- **Analyse d'impact climatique** : √âvaluation des cons√©quences du r√©chauffement climatique sur les villes
- **Recommandations durables** : Conseils concrets pour rendre les villes plus r√©silientes
- **Projets ONU** : D√©couverte d'initiatives des Nations Unies pertinentes
- **Validation SDG11** : Analyse de l'alignement avec l'ODD 11 (Villes et communaut√©s durables)
- **Multi-providers** : Support pour Groq et WatsonX

## üõ†Ô∏è Installation

### Pr√©requis

- Python 3.8+
- Node.js 18+ (pour le frontend)
- Compte Groq (optionnel)
- Compte WatsonX (optionnel)

### Backend

1. Naviguez vers le dossier backend :
```bash
cd backend
```

2. Installez les d√©pendances Python :
```bash
pip install -r requirements.txt
```

3. Configurez les variables d'environnement en cr√©ant un fichier `.env` √† la racine du projet :
```bash
# Copiez le fichier d'exemple
cp env.example .env

# Puis √©ditez le fichier .env avec vos vraies valeurs
```

4. Lancez le serveur backend :
```bash
uvicorn api:app --reload
```

### Frontend

1. Naviguez vers le dossier frontend :
```bash
cd the-hive
```

2. Installez les d√©pendances Node.js :
```bash
npm install
```

3. Lancez le serveur de d√©veloppement :
```bash
npm run dev
```

## ü§ñ Utilisation des Providers d'IA

### Configuration des mod√®les

Vous pouvez configurer les mod√®les par d√©faut dans votre fichier `.env` :

```bash
# Provider par d√©faut
DEFAULT_PROVIDER=groq  # ou watsonx

# Mod√®les par d√©faut pour chaque provider
DEFAULT_GROQ_MODEL=qwen/qwen3-32b
DEFAULT_WATSONX_MODEL=llama-3-3-70b-instruct

# Mod√®le sp√©cifique pour l'agent des projets UN (optionnel)
UN_PROJECTS_MODEL=llama-3.1-8b-instant
```

### Groq

Groq est le provider par d√©faut. Il offre des performances rapides et une bonne qualit√© de r√©ponse.

**Configuration requise :**
- `GROQ_API_KEY` dans le fichier `.env`

**Utilisation :**
```python
from agents import run_climate_agents

# Utilisation par d√©faut (selon DEFAULT_PROVIDER)
result = await run_climate_agents("Paris")

# Sp√©cification explicite
result = await run_climate_agents("Paris", provider="groq")
```

### WatsonX

WatsonX d'IBM offre des mod√®les sp√©cialis√©s et des capacit√©s avanc√©es d'IA.

**Configuration requise :**
- `WATSONX_PROJECT_ID` dans le fichier `.env`
- `WATSONX_API_KEY` dans le fichier `.env`
- `WATSONX_API_URL` (optionnel) dans le fichier `.env`

**Utilisation :**
```python
from agents import run_climate_agents

# Utilisation avec WatsonX
result = await run_climate_agents("Paris", provider="watsonx")
```

### API REST

L'API utilise automatiquement le provider configur√© dans le fichier `.env` :

```bash
curl -X POST "http://localhost:8000/climate-impact" \
  -H "Content-Type: application/json" \
  -d '{"city": "Paris"}'
```

## üì° Endpoints API

### POST /climate-impact
Analyse l'impact du changement climatique sur une ville.

**Param√®tres :**
- `city` (requis) : Nom de la ville

### POST /recommendations
Fournit des recommandations pour rendre une ville plus durable.

**Param√®tres :**
- `city` (requis) : Nom de la ville
- `question` (optionnel) : Question sp√©cifique pour validation SDG11

### POST /un-projects
Liste les projets ONU pertinents pour une ville.

**Param√®tres :**
- `city` (requis) : Nom de la ville

### POST /sdg11-validation
Valide si une proposition est align√©e avec l'ODD 11.

**Param√®tres :**
- `city` (requis) : Nom de la ville
- `question` (requis) : Proposition √† valider

## üß™ Tests

Pour tester les agents, vous pouvez utiliser directement les fonctions Python ou les endpoints API.

## üîß Configuration Avanc√©e

### Mod√®les disponibles

**Groq :**
- `qwen/qwen3-32b` (par d√©faut)
- `llama-3.1-8b-instant`
- Autres mod√®les Groq disponibles

**WatsonX :**
- `llama-3-3-70b-instruct` (par d√©faut)
- `ibm/granite-3-8b-instruct`
- `meta-llama/llama-3-2-11b-vision-instruct` (pour les images)
- Autres mod√®les WatsonX disponibles

### Personnalisation des mod√®les

Vous pouvez sp√©cifier un mod√®le particulier :

```python
from agents import get_model

# Mod√®le Groq sp√©cifique
model = get_model("groq", "llama-3.1-8b-instant")

# Mod√®le WatsonX sp√©cifique
model = get_model("watsonx", "ibm/granite-3-3-8b-instruct")

# Utilisation du mod√®le par d√©faut (selon DEFAULT_PROVIDER)
model = get_model()
```

### Variables d'environnement disponibles

| Variable | Description | D√©faut |
|----------|-------------|---------|
| `DEFAULT_PROVIDER` | Provider par d√©faut (groq/watsonx) | groq |
| `DEFAULT_GROQ_MODEL` | Mod√®le Groq par d√©faut | qwen/qwen3-32b |
| `DEFAULT_WATSONX_MODEL` | Mod√®le WatsonX par d√©faut | llama-3-3-70b-instruct |
| `UN_PROJECTS_MODEL` | Mod√®le sp√©cifique pour les projets UN | (utilise le mod√®le par d√©faut) |

## üåç Objectifs de D√©veloppement Durable (ODD)

Le projet est align√© avec l'ODD 11 "Villes et communaut√©s durables" et utilise les indicateurs officiels de l'ONU pour √©valuer les propositions et recommandations.

## üìù Licence

Ce projet est sous licence MIT.

## ü§ù Contribution

Les contributions sont les bienvenues ! N'h√©sitez pas √† ouvrir une issue ou √† soumettre une pull request.

## üìû Support

Pour toute question ou probl√®me, veuillez ouvrir une issue sur GitHub.
